{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma rede neural pra gerar imagens e outra para discriminar se a imagem gerada é a artificial ou se é uma imagem real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob         # glob e imageio pra gerar gif com as minhas épocas da rede treinada ao final\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL          #pra manipular imagens\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "train_images = (train_images - 127.5) / 127.5           #Normalizando as imagens para irem de -1 a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo algumas constantes padrão do tamanho do meu conjunto (60k imagens)\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256        # A quantidade de bits que ele varia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É utilizado o tensor_slices pra fazer uma transformação no meu dataset, usando o shuffle\n",
    "# pra trazer o tamanho do meu conjunto e o batch pra normalizar esses 256 pixels.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Construindo camada por camada do meu modelo GERADOR de imagens.\n",
    " def make_generator_model():\n",
    "    model = tf.keras.Sequential()      #vamos usar o modelo do tipo Sequential e ir add as camadas uma a uma\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))       #A função assert é pra comparar e ver se estamos atingindo o esperado\n",
    "    assert model.output_shape == (None, 7, 7, 256)          #None é o tamanho do Batch\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1,1), padding=\"same\", use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2,2), padding=\"same\", use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2,2), padding=\"same\", use_bias=False, activation=\"tanh\"))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18f4fb11f10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "# essa é a visão de uma imagem nunca treinada, gerada a partir de um não-treinamento. \n",
    "# É a rede neural do jeito que veio ao mundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passado isso, vou criar o modelo discriminador. vai ter menos camadas do que o gerador, pois discriminar\n",
    "# é mais fácil do que gerar.\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28,28,1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00183487]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Construídas as duas funções, vamos instanciar o modelo discriminador\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "\n",
    "print(decision)\n",
    "#como o valor gerado abaixo foi positivo, significa que o meu discriminador entendeu que a figura crua \n",
    "# acima era real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toda rede neural trabalha com uma função de custo. Usaremos uma famosa função chamada CrossEntropy.\n",
    "#Em seguida serão criadas funções de custo tanto pro gerador quanto pro discriminador.\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Só destacar que pro gerador, só me importa o fakeoutput. Só o discriminador que vai precisar\n",
    "#  ter o real e o fake pra comparar\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalmente utilizamos o otimizador Adam. Aplicaremos tanto pro gerador quanto pro discriminador\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É muito importante, quando construindo uma rede neural, criarmos um checkpoint.\n",
    "# Pois, se der algum problema na máquina ou internet etc, não precisaremos recomeçar do zero o treinamento.\n",
    "\n",
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um GIF, para que vejamos a evolução das imagens em forma de uma animação.\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function    #aqui eu passo um decorator function só pra ele dizer que esse cara foi compilado em algum momento.\n",
    "#São boas práticas quando se trabalha com deep learning. Usado pra criar modelos portáteis do TensorFlow.\n",
    "\n",
    "#Aqui vou criar uma função de etapas de treinamento, que vai receber as imagens e no final vai aplicar os otimizadores\n",
    "# e criando as tuplas.\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: #basicamente estamos resumindo métodos muito\n",
    "        generated_images = generator(noise, training=True)              #grandes, classes ou até nomes de arquivos \n",
    "                                                                        #em pequenos valores de variáveis (gen e disc)\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#De fato temos agora a função de treino, que vai receber tanto os datasets quanto as épocas\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        display.clear_output(wait=True)                         #Aqui estamos produzindo as imagens pro GIF\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:                               #salvando o modelo a cada 15 épocas\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "        print(\"Time for epoch {} is {} sec\".format(epoch + 1, time.time()-start))\n",
    "    \n",
    "    display.clear_output(wait=True)                             #São geradas as imagens e depois salvas\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essa função é a que vai gerar as imagens, recebendo o modelo, a qtd de épocas e o test_input\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.savefig(\"image_at_epoch_{:04d}.png\".format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando o treinamento, vamos receber de output o tempo que ele demorou e 4x4 imagens.\n",
    "#No diretório, dá pra ver a evolução das imagens. Mas ainda assim, com 50 épocas, ainda estamos longe de ficar bom.\n",
    "#Teria que aumentar o número de épocas.\n",
    "\n",
    "#Do professor levou 2h30.\n",
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7e5e0eaa77a28125227fb7ae19e78585bc0f4691d77dafd52dbfc5225ddb4e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
